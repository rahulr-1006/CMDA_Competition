{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 877,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1:\n",
    "# Outcome Variables (Targets):\n",
    "# Maternal mortality rate\n",
    "# Infant mortality rate\n",
    "# Predictor Variables:\n",
    "# Income metrics (e.g., average income, income inequality measures)\n",
    "# Educational attainment (e.g., college attainment rates)\n",
    "# Interaction term: Income Ã— Educational Attainment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/rahulramakrishnan/Documents/love_hate_relationship/competitions/cmda_competition/datasets/custom/final_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['year', 'all_infant_deaths_all_mothers', 'all_infant_deaths_all_races__hispanic', 'all_infant_deaths_all_races__hispanic__central_and_south_american', 'all_infant_deaths_all_races__hispanic__cuban', 'all_infant_deaths_all_races__hispanic__mexican', 'all_infant_deaths_all_races__hispanic__other', 'all_infant_deaths_all_races__hispanic__puerto_rican', 'all_infant_deaths_american_indian_and_alaska_native', 'all_infant_deaths_american_indian_and_alaska_native__non-hispanic', 'all_infant_deaths_american_indian_and_alaska_native_only', 'all_infant_deaths_american_indian_and_alaska_native_only__non-hispanic', 'all_infant_deaths_asian_only__non-hispanic', 'all_infant_deaths_asian_or_pacific_islander', 'all_infant_deaths_asian_or_pacific_islander__non-hispanic', 'all_infant_deaths_black', 'all_infant_deaths_black__non-hispanic', 'all_infant_deaths_black_only', 'all_infant_deaths_black_only__non-hispanic', 'all_infant_deaths_native_hawaiian_or_other_pacific_islander_only__non-hispanic', 'all_infant_deaths_white', 'all_infant_deaths_white__non-hispanic', 'all_infant_deaths_white_only', 'all_infant_deaths_white_only__non-hispanic', 'neonatal_deaths_all_mothers', 'neonatal_deaths_all_races__hispanic', 'neonatal_deaths_all_races__hispanic__central_and_south_american', 'neonatal_deaths_all_races__hispanic__cuban', 'neonatal_deaths_all_races__hispanic__mexican', 'neonatal_deaths_all_races__hispanic__other', 'neonatal_deaths_all_races__hispanic__puerto_rican', 'neonatal_deaths_american_indian_and_alaska_native', 'neonatal_deaths_american_indian_and_alaska_native__non-hispanic', 'neonatal_deaths_american_indian_and_alaska_native_only', 'neonatal_deaths_american_indian_and_alaska_native_only__non-hispanic', 'neonatal_deaths_asian_only__non-hispanic', 'neonatal_deaths_asian_or_pacific_islander', 'neonatal_deaths_asian_or_pacific_islander__non-hispanic', 'neonatal_deaths_black', 'neonatal_deaths_black__non-hispanic', 'neonatal_deaths_black_only', 'neonatal_deaths_black_only__non-hispanic', 'neonatal_deaths_native_hawaiian_or_other_pacific_islander_only__non-hispanic', 'neonatal_deaths_white', 'neonatal_deaths_white__non-hispanic', 'neonatal_deaths_white_only', 'neonatal_deaths_white_only__non-hispanic', 'postneonatal_deaths_all_mothers', 'postneonatal_deaths_all_races__hispanic', 'postneonatal_deaths_all_races__hispanic__central_and_south_american', 'postneonatal_deaths_all_races__hispanic__cuban', 'postneonatal_deaths_all_races__hispanic__mexican', 'postneonatal_deaths_all_races__hispanic__other', 'postneonatal_deaths_all_races__hispanic__puerto_rican', 'postneonatal_deaths_american_indian_and_alaska_native', 'postneonatal_deaths_american_indian_and_alaska_native__non-hispanic', 'postneonatal_deaths_american_indian_and_alaska_native_only', 'postneonatal_deaths_american_indian_and_alaska_native_only__non-hispanic', 'postneonatal_deaths_asian_only__non-hispanic', 'postneonatal_deaths_asian_or_pacific_islander', 'postneonatal_deaths_asian_or_pacific_islander__non-hispanic', 'postneonatal_deaths_black', 'postneonatal_deaths_black__non-hispanic', 'postneonatal_deaths_black_only', 'postneonatal_deaths_black_only__non-hispanic', 'postneonatal_deaths_native_hawaiian_or_other_pacific_islander_only__non-hispanic', 'postneonatal_deaths_white', 'postneonatal_deaths_white__non-hispanic', 'postneonatal_deaths_white_only', 'postneonatal_deaths_white_only__non-hispanic', 'asthma_episode/attack_all_ages', 'asthma_episode/attack_asian', 'asthma_episode/attack_black', 'asthma_episode/attack_female', 'asthma_episode/attack_other', 'asthma_episode/attack_white', 'cervical_cancer_all_ages', 'cervical_cancer_asian', 'cervical_cancer_black', 'cervical_cancer_female', 'cervical_cancer_other', 'cervical_cancer_white', 'copd__emphysema__chronic_bronchitis_all_ages', 'copd__emphysema__chronic_bronchitis_asian', 'copd__emphysema__chronic_bronchitis_black', 'copd__emphysema__chronic_bronchitis_female', 'copd__emphysema__chronic_bronchitis_other', 'copd__emphysema__chronic_bronchitis_white', 'coronary_heart_disease_all_ages', 'coronary_heart_disease_asian', 'coronary_heart_disease_black', 'coronary_heart_disease_female', 'coronary_heart_disease_other', 'coronary_heart_disease_white', 'current_cigarette_smoking_all_ages', 'current_cigarette_smoking_asian', 'current_cigarette_smoking_black', 'current_cigarette_smoking_female', 'current_cigarette_smoking_other', 'current_cigarette_smoking_white', 'diagnosed_diabetes__self-reported_all_ages', 'diagnosed_diabetes__self-reported_asian', 'diagnosed_diabetes__self-reported_black', 'diagnosed_diabetes__self-reported_female', 'diagnosed_diabetes__self-reported_other', 'diagnosed_diabetes__self-reported_white', 'hypertension_diagnosis__self-reported_all_ages', 'hypertension_diagnosis__self-reported_asian', 'hypertension_diagnosis__self-reported_black', 'hypertension_diagnosis__self-reported_female', 'hypertension_diagnosis__self-reported_other', 'hypertension_diagnosis__self-reported_white', 'obesity__self-reported_all_ages', 'obesity__self-reported_asian', 'obesity__self-reported_black', 'obesity__self-reported_female', 'obesity__self-reported_other', 'obesity__self-reported_white', 'total_weekly_wage', 'white_weekly_wage', 'black_weekly_wage', 'asian_weekly_wage', 'hispanic_weekly_wage', 'Data As Of', 'Jurisdiction', 'Group', 'Subgroup', 'Month of Death', 'Time Period', 'Month Ending Date', 'Maternal Deaths', 'Live Births', 'Maternal Mortality Rate', 'Footnote', 'college_col_white', 'college_mkt_white', 'college_dif_white', 'college_col_hispa', 'college_mkt_hispa', 'college_dif_hispa', 'college_col_black', 'college_mkt_black', 'college_dif_black', 'college_col_asian', 'college_mkt_asian', 'college_dif_asian', 'college_col_amind', 'college_mkt_amind', 'college_dif_amind', 'college_col_pacis', 'college_mkt_pacis', 'college_dif_pacis', 'college_col_twora', 'college_mkt_twora', 'college_dif_twora']\n"
     ]
    }
   ],
   "source": [
    "columns_list = df.columns.tolist()\n",
    "print(columns_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after cleaning:\n",
      "year                                                                 0\n",
      "all_infant_deaths_all_mothers                                        0\n",
      "all_infant_deaths_all_races__hispanic                                0\n",
      "all_infant_deaths_all_races__hispanic__central_and_south_american    0\n",
      "all_infant_deaths_all_races__hispanic__cuban                         0\n",
      "                                                                    ..\n",
      "college_mkt_pacis                                                    0\n",
      "college_dif_pacis                                                    0\n",
      "college_col_twora                                                    0\n",
      "college_mkt_twora                                                    0\n",
      "college_dif_twora                                                    0\n",
      "Length: 155, dtype: int64\n",
      "\n",
      "Summary statistics after outlier handling:\n",
      "             year  all_infant_deaths_all_mothers  \\\n",
      "count     8.00000                       8.000000   \n",
      "mean   2020.50000                       5.512500   \n",
      "std       2.44949                       0.164208   \n",
      "min    2017.00000                       5.400000   \n",
      "25%    2018.75000                       5.400000   \n",
      "50%    2020.50000                       5.400000   \n",
      "75%    2022.25000                       5.625000   \n",
      "max    2024.00000                       5.800000   \n",
      "\n",
      "       all_infant_deaths_all_races__hispanic  \\\n",
      "count                               8.000000   \n",
      "mean                                4.862500   \n",
      "std                                 0.130247   \n",
      "min                                 4.700000   \n",
      "25%                                 4.800000   \n",
      "50%                                 4.800000   \n",
      "75%                                 4.925000   \n",
      "max                                 5.100000   \n",
      "\n",
      "       all_infant_deaths_all_races__hispanic__central_and_south_american  \\\n",
      "count                                           8.000000                   \n",
      "mean                                            4.212500                   \n",
      "std                                             0.210017                   \n",
      "min                                             3.900000                   \n",
      "25%                                             4.150000                   \n",
      "50%                                             4.200000                   \n",
      "75%                                             4.275000                   \n",
      "max                                             4.500000                   \n",
      "\n",
      "       all_infant_deaths_all_races__hispanic__cuban  \\\n",
      "count                                      8.000000   \n",
      "mean                                       3.812500   \n",
      "std                                        0.253194   \n",
      "min                                        3.600000   \n",
      "25%                                        3.600000   \n",
      "50%                                        3.700000   \n",
      "75%                                        4.025000   \n",
      "max                                        4.200000   \n",
      "\n",
      "       all_infant_deaths_all_races__hispanic__mexican  \\\n",
      "count                                        8.000000   \n",
      "mean                                         4.912500   \n",
      "std                                          0.112599   \n",
      "min                                          4.700000   \n",
      "25%                                          4.900000   \n",
      "50%                                          4.900000   \n",
      "75%                                          4.925000   \n",
      "max                                          5.100000   \n",
      "\n",
      "       all_infant_deaths_all_races__hispanic__other  \\\n",
      "count                                       8.00000   \n",
      "mean                                        5.00000   \n",
      "std                                         0.36645   \n",
      "min                                         4.70000   \n",
      "25%                                         4.70000   \n",
      "50%                                         4.80000   \n",
      "75%                                         5.40000   \n",
      "max                                         5.50000   \n",
      "\n",
      "       all_infant_deaths_all_races__hispanic__puerto_rican  \\\n",
      "count                                           8.000000     \n",
      "mean                                            6.125000     \n",
      "std                                             0.254951     \n",
      "min                                             5.600000     \n",
      "25%                                             6.100000     \n",
      "50%                                             6.100000     \n",
      "75%                                             6.225000     \n",
      "max                                             6.500000     \n",
      "\n",
      "       all_infant_deaths_american_indian_and_alaska_native  \\\n",
      "count                                           8.000000     \n",
      "mean                                            7.625000     \n",
      "std                                             0.281577     \n",
      "min                                             7.500000     \n",
      "25%                                             7.500000     \n",
      "50%                                             7.500000     \n",
      "75%                                             7.550000     \n",
      "max                                             8.300000     \n",
      "\n",
      "       all_infant_deaths_american_indian_and_alaska_native__non-hispanic  ...  \\\n",
      "count                                           8.000000                  ...   \n",
      "mean                                            7.900000                  ...   \n",
      "std                                             0.427618                  ...   \n",
      "min                                             7.700000                  ...   \n",
      "25%                                             7.700000                  ...   \n",
      "50%                                             7.700000                  ...   \n",
      "75%                                             7.800000                  ...   \n",
      "max                                             8.900000                  ...   \n",
      "\n",
      "       college_dif_asian  college_col_amind  college_mkt_amind  \\\n",
      "count           8.000000           8.000000           8.000000   \n",
      "mean           -1.353938           2.486212           1.292032   \n",
      "std             0.000000           0.000000           0.000000   \n",
      "min            -1.353938           2.486212           1.292032   \n",
      "25%            -1.353938           2.486212           1.292032   \n",
      "50%            -1.353938           2.486212           1.292032   \n",
      "75%            -1.353938           2.486212           1.292032   \n",
      "max            -1.353938           2.486212           1.292032   \n",
      "\n",
      "       college_dif_amind  college_col_pacis  college_mkt_pacis  \\\n",
      "count           8.000000           8.000000       8.000000e+00   \n",
      "mean            1.194181           0.315793       1.845440e-01   \n",
      "std             0.000000           0.000000       2.967196e-17   \n",
      "min             1.194181           0.315793       1.845440e-01   \n",
      "25%             1.194181           0.315793       1.845440e-01   \n",
      "50%             1.194181           0.315793       1.845440e-01   \n",
      "75%             1.194181           0.315793       1.845440e-01   \n",
      "max             1.194181           0.315793       1.845440e-01   \n",
      "\n",
      "       college_dif_pacis  college_col_twora  college_mkt_twora  \\\n",
      "count            8.00000       8.000000e+00           8.000000   \n",
      "mean             0.13125       3.115245e+00           2.546376   \n",
      "std              0.00000       4.747513e-16           0.000000   \n",
      "min              0.13125       3.115245e+00           2.546376   \n",
      "25%              0.13125       3.115245e+00           2.546376   \n",
      "50%              0.13125       3.115245e+00           2.546376   \n",
      "75%              0.13125       3.115245e+00           2.546376   \n",
      "max              0.13125       3.115245e+00           2.546376   \n",
      "\n",
      "       college_dif_twora  \n",
      "count       8.000000e+00  \n",
      "mean        5.688688e-01  \n",
      "std         1.186878e-16  \n",
      "min         5.688688e-01  \n",
      "25%         5.688688e-01  \n",
      "50%         5.688688e-01  \n",
      "75%         5.688688e-01  \n",
      "max         5.688688e-01  \n",
      "\n",
      "[8 rows x 155 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "import pandas as pd\n",
    "\n",
    "def fill_missing_values(df):\n",
    "    \"\"\"\n",
    "    Fill missing values in the DataFrame.\n",
    "    - Numeric columns: Use group-based median for better precision.\n",
    "    - Categorical columns: Use mode.\n",
    "    \"\"\"\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype in ['int64', 'float64']:  # Numeric columns\n",
    "            # Use group-based median for imputation\n",
    "            if 'year' in df.columns:  # Check if \"year\" column exists for grouping\n",
    "                df[col] = df.groupby('year')[col].transform(lambda x: x.fillna(x.median()))\n",
    "            else:\n",
    "                df[col].fillna(df[col].median(), inplace=True)\n",
    "        else:  # Non-numeric columns\n",
    "            df[col].fillna(df[col].mode()[0], inplace=True)  # Use mode for categorical columns\n",
    "    return df\n",
    "\n",
    "def handle_outliers(df, threshold=3):\n",
    "    \"\"\"\n",
    "    Handle outliers in the DataFrame.\n",
    "    - Replace extreme outliers with group-based median values for numeric columns.\n",
    "    \"\"\"\n",
    "    numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns  # Select numeric columns\n",
    "    for col in numeric_cols:\n",
    "        # Calculate Z-scores\n",
    "        if df[col].notnull().sum() > 0:  # Ensure column has non-null values\n",
    "            z_scores = zscore(df[col].dropna())\n",
    "            outliers = np.abs(z_scores) > threshold  # Identify outliers beyond threshold\n",
    "            if outliers.any():\n",
    "                # Replace outliers with group-based median if 'year' exists, else global median\n",
    "                if 'year' in df.columns:\n",
    "                    median = df.groupby('year')[col].transform('median')\n",
    "                    df.loc[outliers, col] = median\n",
    "                else:\n",
    "                    median = df[col].median()\n",
    "                    df.loc[outliers, col] = median\n",
    "    return df\n",
    "\n",
    "# Apply cleaning steps\n",
    "# Load your DataFrame here\n",
    "\n",
    "# Handle missing values and outliers\n",
    "df = fill_missing_values(df)\n",
    "df = handle_outliers(df)\n",
    "\n",
    "# Validate the cleaning\n",
    "print(\"Missing values after cleaning:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nSummary statistics after outlier handling:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Engineering Completed. Processed DataFrame saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_s/9c640jvj65z4l9y9z5y799440000gn/T/ipykernel_92435/463496445.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{group}_income_college_ratio'] = df[f'{group}_weekly_wage'] / (df[f'college_col_{col_suffix}'] + 1e-6)\n",
      "/var/folders/_s/9c640jvj65z4l9y9z5y799440000gn/T/ipykernel_92435/463496445.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{group}_income_edu_interaction'] = df[f'{group}_weekly_wage'] * df[f'college_col_{col_suffix}']\n",
      "/var/folders/_s/9c640jvj65z4l9y9z5y799440000gn/T/ipykernel_92435/463496445.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{group}_income_college_ratio'] = df[f'{group}_weekly_wage'] / (df[f'college_col_{col_suffix}'] + 1e-6)\n",
      "/var/folders/_s/9c640jvj65z4l9y9z5y799440000gn/T/ipykernel_92435/463496445.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{group}_income_edu_interaction'] = df[f'{group}_weekly_wage'] * df[f'college_col_{col_suffix}']\n",
      "/var/folders/_s/9c640jvj65z4l9y9z5y799440000gn/T/ipykernel_92435/463496445.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{group}_income_college_ratio'] = df[f'{group}_weekly_wage'] / (df[f'college_col_{col_suffix}'] + 1e-6)\n",
      "/var/folders/_s/9c640jvj65z4l9y9z5y799440000gn/T/ipykernel_92435/463496445.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{group}_income_edu_interaction'] = df[f'{group}_weekly_wage'] * df[f'college_col_{col_suffix}']\n",
      "/var/folders/_s/9c640jvj65z4l9y9z5y799440000gn/T/ipykernel_92435/463496445.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{group}_income_college_ratio'] = df[f'{group}_weekly_wage'] / (df[f'college_col_{col_suffix}'] + 1e-6)\n",
      "/var/folders/_s/9c640jvj65z4l9y9z5y799440000gn/T/ipykernel_92435/463496445.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{group}_income_edu_interaction'] = df[f'{group}_weekly_wage'] * df[f'college_col_{col_suffix}']\n",
      "/var/folders/_s/9c640jvj65z4l9y9z5y799440000gn/T/ipykernel_92435/463496445.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['neonatal_to_postneonatal_ratio'] = df['neonatal_deaths_all_mothers'] / (df['postneonatal_deaths_all_mothers'] + 1e-6)\n",
      "/var/folders/_s/9c640jvj65z4l9y9z5y799440000gn/T/ipykernel_92435/463496445.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['maternal_mortality_per_birth'] = df['Maternal Deaths'] / (df['Live Births'] + 1e-6)\n",
      "/var/folders/_s/9c640jvj65z4l9y9z5y799440000gn/T/ipykernel_92435/463496445.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['total_infant_mortality'] = df[infant_death_columns].sum(axis=1)\n",
      "/var/folders/_s/9c640jvj65z4l9y9z5y799440000gn/T/ipykernel_92435/463496445.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['black_white_infant_mortality_ratio'] = df['all_infant_deaths_black'] / (df['all_infant_deaths_white'] + 1e-6)\n",
      "/var/folders/_s/9c640jvj65z4l9y9z5y799440000gn/T/ipykernel_92435/463496445.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['white_black_wage_gap'] = df['white_weekly_wage'] - df['black_weekly_wage']\n",
      "/var/folders/_s/9c640jvj65z4l9y9z5y799440000gn/T/ipykernel_92435/463496445.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['income_inequality'] = df[wage_columns].max(axis=1) / (df[wage_columns].min(axis=1) + 1e-6)\n",
      "/var/folders/_s/9c640jvj65z4l9y9z5y799440000gn/T/ipykernel_92435/463496445.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['chronic_risk_index'] = df[chronic_columns].sum(axis=1) / (df['Live Births'] + 1e-6)\n",
      "/var/folders/_s/9c640jvj65z4l9y9z5y799440000gn/T/ipykernel_92435/463496445.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'log_{col}'] = np.log1p(df[col])\n",
      "/var/folders/_s/9c640jvj65z4l9y9z5y799440000gn/T/ipykernel_92435/463496445.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'log_{col}'] = np.log1p(df[col])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming `df` is the DataFrame loaded with your dataset\n",
    "\n",
    "# 1. Income-Education Interaction Terms\n",
    "for group, col_suffix in [('white', 'white'), ('black', 'black'), ('asian', 'asian'), ('hispanic', 'hispa')]:\n",
    "    # Income-to-college ratios\n",
    "    df[f'{group}_income_college_ratio'] = df[f'{group}_weekly_wage'] / (df[f'college_col_{col_suffix}'] + 1e-6)\n",
    "\n",
    "    # Interaction between income and education levels\n",
    "    df[f'{group}_income_edu_interaction'] = df[f'{group}_weekly_wage'] * df[f'college_col_{col_suffix}']\n",
    "\n",
    "# 2. Mortality Metrics\n",
    "# Neonatal vs. Postneonatal deaths ratio\n",
    "if 'neonatal_deaths_all_mothers' in df.columns and 'postneonatal_deaths_all_mothers' in df.columns:\n",
    "    df['neonatal_to_postneonatal_ratio'] = df['neonatal_deaths_all_mothers'] / (df['postneonatal_deaths_all_mothers'] + 1e-6)\n",
    "\n",
    "# Maternal mortality per live birth\n",
    "if 'Maternal Deaths' in df.columns and 'Live Births' in df.columns:\n",
    "    df['maternal_mortality_per_birth'] = df['Maternal Deaths'] / (df['Live Births'] + 1e-6)\n",
    "\n",
    "# Total infant mortality for all races\n",
    "infant_death_columns = [col for col in df.columns if 'all_infant_deaths' in col]\n",
    "df['total_infant_mortality'] = df[infant_death_columns].sum(axis=1)\n",
    "\n",
    "# 3. Racial Disparity Metrics\n",
    "# Black vs. White infant mortality ratio\n",
    "if 'all_infant_deaths_black' in df.columns and 'all_infant_deaths_white' in df.columns:\n",
    "    df['black_white_infant_mortality_ratio'] = df['all_infant_deaths_black'] / (df['all_infant_deaths_white'] + 1e-6)\n",
    "\n",
    "# Wage gaps between racial groups\n",
    "if 'white_weekly_wage' in df.columns and 'black_weekly_wage' in df.columns:\n",
    "    df['white_black_wage_gap'] = df['white_weekly_wage'] - df['black_weekly_wage']\n",
    "\n",
    "# 4. Income Inequality Metrics\n",
    "wage_columns = [f'{group}_weekly_wage' for group in ['white', 'black', 'asian', 'hispanic']]\n",
    "if all(col in df.columns for col in wage_columns):\n",
    "    df['income_inequality'] = df[wage_columns].max(axis=1) / (df[wage_columns].min(axis=1) + 1e-6)\n",
    "\n",
    "# 5. Chronic Risk Aggregates\n",
    "chronic_columns = [\n",
    "    'obesity__self-reported_all_ages', 'current_cigarette_smoking_all_ages', 'hypertension_diagnosis__self-reported_all_ages'\n",
    "]\n",
    "if all(col in df.columns for col in chronic_columns):\n",
    "    df['chronic_risk_index'] = df[chronic_columns].sum(axis=1) / (df['Live Births'] + 1e-6)\n",
    "\n",
    "# 6. Log Transformations (optional for skewed variables)\n",
    "log_transform_columns = ['total_weekly_wage', 'Maternal Mortality Rate']\n",
    "for col in log_transform_columns:\n",
    "    if col in df.columns:\n",
    "        df[f'log_{col}'] = np.log1p(df[col])\n",
    "\n",
    "\n",
    "print(\"Feature Engineering Completed. Processed DataFrame saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['year', 'all_infant_deaths_all_mothers', 'all_infant_deaths_all_races__hispanic', 'all_infant_deaths_all_races__hispanic__central_and_south_american', 'all_infant_deaths_all_races__hispanic__cuban', 'all_infant_deaths_all_races__hispanic__mexican', 'all_infant_deaths_all_races__hispanic__other', 'all_infant_deaths_all_races__hispanic__puerto_rican', 'all_infant_deaths_american_indian_and_alaska_native', 'all_infant_deaths_american_indian_and_alaska_native__non-hispanic', 'all_infant_deaths_american_indian_and_alaska_native_only', 'all_infant_deaths_american_indian_and_alaska_native_only__non-hispanic', 'all_infant_deaths_asian_only__non-hispanic', 'all_infant_deaths_asian_or_pacific_islander', 'all_infant_deaths_asian_or_pacific_islander__non-hispanic', 'all_infant_deaths_black', 'all_infant_deaths_black__non-hispanic', 'all_infant_deaths_black_only', 'all_infant_deaths_black_only__non-hispanic', 'all_infant_deaths_native_hawaiian_or_other_pacific_islander_only__non-hispanic', 'all_infant_deaths_white', 'all_infant_deaths_white__non-hispanic', 'all_infant_deaths_white_only', 'all_infant_deaths_white_only__non-hispanic', 'neonatal_deaths_all_mothers', 'neonatal_deaths_all_races__hispanic', 'neonatal_deaths_all_races__hispanic__central_and_south_american', 'neonatal_deaths_all_races__hispanic__cuban', 'neonatal_deaths_all_races__hispanic__mexican', 'neonatal_deaths_all_races__hispanic__other', 'neonatal_deaths_all_races__hispanic__puerto_rican', 'neonatal_deaths_american_indian_and_alaska_native', 'neonatal_deaths_american_indian_and_alaska_native__non-hispanic', 'neonatal_deaths_american_indian_and_alaska_native_only', 'neonatal_deaths_american_indian_and_alaska_native_only__non-hispanic', 'neonatal_deaths_asian_only__non-hispanic', 'neonatal_deaths_asian_or_pacific_islander', 'neonatal_deaths_asian_or_pacific_islander__non-hispanic', 'neonatal_deaths_black', 'neonatal_deaths_black__non-hispanic', 'neonatal_deaths_black_only', 'neonatal_deaths_black_only__non-hispanic', 'neonatal_deaths_native_hawaiian_or_other_pacific_islander_only__non-hispanic', 'neonatal_deaths_white', 'neonatal_deaths_white__non-hispanic', 'neonatal_deaths_white_only', 'neonatal_deaths_white_only__non-hispanic', 'postneonatal_deaths_all_mothers', 'postneonatal_deaths_all_races__hispanic', 'postneonatal_deaths_all_races__hispanic__central_and_south_american', 'postneonatal_deaths_all_races__hispanic__cuban', 'postneonatal_deaths_all_races__hispanic__mexican', 'postneonatal_deaths_all_races__hispanic__other', 'postneonatal_deaths_all_races__hispanic__puerto_rican', 'postneonatal_deaths_american_indian_and_alaska_native', 'postneonatal_deaths_american_indian_and_alaska_native__non-hispanic', 'postneonatal_deaths_american_indian_and_alaska_native_only', 'postneonatal_deaths_american_indian_and_alaska_native_only__non-hispanic', 'postneonatal_deaths_asian_only__non-hispanic', 'postneonatal_deaths_asian_or_pacific_islander', 'postneonatal_deaths_asian_or_pacific_islander__non-hispanic', 'postneonatal_deaths_black', 'postneonatal_deaths_black__non-hispanic', 'postneonatal_deaths_black_only', 'postneonatal_deaths_black_only__non-hispanic', 'postneonatal_deaths_native_hawaiian_or_other_pacific_islander_only__non-hispanic', 'postneonatal_deaths_white', 'postneonatal_deaths_white__non-hispanic', 'postneonatal_deaths_white_only', 'postneonatal_deaths_white_only__non-hispanic', 'asthma_episode/attack_all_ages', 'asthma_episode/attack_asian', 'asthma_episode/attack_black', 'asthma_episode/attack_female', 'asthma_episode/attack_other', 'asthma_episode/attack_white', 'cervical_cancer_all_ages', 'cervical_cancer_asian', 'cervical_cancer_black', 'cervical_cancer_female', 'cervical_cancer_other', 'cervical_cancer_white', 'copd__emphysema__chronic_bronchitis_all_ages', 'copd__emphysema__chronic_bronchitis_asian', 'copd__emphysema__chronic_bronchitis_black', 'copd__emphysema__chronic_bronchitis_female', 'copd__emphysema__chronic_bronchitis_other', 'copd__emphysema__chronic_bronchitis_white', 'coronary_heart_disease_all_ages', 'coronary_heart_disease_asian', 'coronary_heart_disease_black', 'coronary_heart_disease_female', 'coronary_heart_disease_other', 'coronary_heart_disease_white', 'current_cigarette_smoking_all_ages', 'current_cigarette_smoking_asian', 'current_cigarette_smoking_black', 'current_cigarette_smoking_female', 'current_cigarette_smoking_other', 'current_cigarette_smoking_white', 'diagnosed_diabetes__self-reported_all_ages', 'diagnosed_diabetes__self-reported_asian', 'diagnosed_diabetes__self-reported_black', 'diagnosed_diabetes__self-reported_female', 'diagnosed_diabetes__self-reported_other', 'diagnosed_diabetes__self-reported_white', 'hypertension_diagnosis__self-reported_all_ages', 'hypertension_diagnosis__self-reported_asian', 'hypertension_diagnosis__self-reported_black', 'hypertension_diagnosis__self-reported_female', 'hypertension_diagnosis__self-reported_other', 'hypertension_diagnosis__self-reported_white', 'obesity__self-reported_all_ages', 'obesity__self-reported_asian', 'obesity__self-reported_black', 'obesity__self-reported_female', 'obesity__self-reported_other', 'obesity__self-reported_white', 'total_weekly_wage', 'white_weekly_wage', 'black_weekly_wage', 'asian_weekly_wage', 'hispanic_weekly_wage', 'Data As Of', 'Jurisdiction', 'Group', 'Subgroup', 'Month of Death', 'Time Period', 'Month Ending Date', 'Maternal Deaths', 'Live Births', 'Maternal Mortality Rate', 'Footnote', 'college_col_white', 'college_mkt_white', 'college_dif_white', 'college_col_hispa', 'college_mkt_hispa', 'college_dif_hispa', 'college_col_black', 'college_mkt_black', 'college_dif_black', 'college_col_asian', 'college_mkt_asian', 'college_dif_asian', 'college_col_amind', 'college_mkt_amind', 'college_dif_amind', 'college_col_pacis', 'college_mkt_pacis', 'college_dif_pacis', 'college_col_twora', 'college_mkt_twora', 'college_dif_twora', 'white_income_college_ratio', 'white_income_edu_interaction', 'black_income_college_ratio', 'black_income_edu_interaction', 'asian_income_college_ratio', 'asian_income_edu_interaction', 'hispanic_income_college_ratio', 'hispanic_income_edu_interaction', 'neonatal_to_postneonatal_ratio', 'maternal_mortality_per_birth', 'total_infant_mortality', 'black_white_infant_mortality_ratio', 'white_black_wage_gap', 'income_inequality', 'chronic_risk_index', 'log_total_weekly_wage', 'log_Maternal Mortality Rate']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {},
   "outputs": [],
   "source": [
    "## scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Child Health Model\n",
      "Linear Regression RMSE: 2.0077810725084944\n",
      "R^2: 0.5666557554288237\n",
      "\n",
      "Child Health Model - Gradient Boosted Regressor\n",
      "RMSE: 3.6062149898339353\n",
      "R^2: -0.3979883421556565\n",
      "Feature: white_income_edu_interaction, Importance: 0.28088505984431594\n",
      "Feature: black_income_edu_interaction, Importance: 0.10490496362588016\n",
      "Feature: asian_income_edu_interaction, Importance: 0.01851392365718559\n",
      "Feature: hispanic_income_edu_interaction, Importance: 0.1077051154189464\n",
      "Feature: white_income_college_ratio, Importance: 0.2125480816452095\n",
      "Feature: black_income_college_ratio, Importance: 0.1460052698781651\n",
      "Feature: asian_income_college_ratio, Importance: 0.020519280149627058\n",
      "Feature: hispanic_income_college_ratio, Importance: 0.011605593463292652\n",
      "Feature: chronic_risk_index, Importance: 0.02395918129347201\n",
      "Feature: income_inequality, Importance: 0.03688975504141511\n",
      "Feature: black_white_infant_mortality_ratio, Importance: 0.03646377598249048\n",
      "Feature: white_black_wage_gap, Importance: 0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "\n",
    "# Define target variables and features\n",
    "features = [\n",
    "    'white_income_edu_interaction', 'black_income_edu_interaction', 'asian_income_edu_interaction', 'hispanic_income_edu_interaction',\n",
    "    'white_income_college_ratio', 'black_income_college_ratio', 'asian_income_college_ratio', 'hispanic_income_college_ratio',\n",
    "    'chronic_risk_index', 'income_inequality', 'black_white_infant_mortality_ratio', 'white_black_wage_gap'\n",
    "]\n",
    "\n",
    "# Maternal health model\n",
    "target_maternal = 'maternal_mortality_per_birth'\n",
    "# Child health model\n",
    "target_child = 'total_infant_mortality'\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train_maternal, y_test_maternal = train_test_split(df[features], df[target_maternal], test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_train_child, y_test_child = train_test_split(df[features], df[target_child], test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Linear Regression\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Child Model\n",
    "lr.fit(X_train_scaled, y_train_child)\n",
    "pred_child = lr.predict(X_test_scaled)\n",
    "print(\"\\nChild Health Model\")\n",
    "print(\"Linear Regression RMSE:\", np.sqrt(mean_squared_error(y_test_child, pred_child)))\n",
    "print(\"R^2:\", r2_score(y_test_child, pred_child))\n",
    "\n",
    "# Gradient Boosted Regressor\n",
    "gbr = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "\n",
    "# Child Model\n",
    "gbr.fit(X_train, y_train_child)\n",
    "pred_child_gbr = gbr.predict(X_test)\n",
    "print(\"\\nChild Health Model - Gradient Boosted Regressor\")\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test_child, pred_child_gbr)))\n",
    "print(\"R^2:\", r2_score(y_test_child, pred_child_gbr))\n",
    "\n",
    "# Feature Importance from Gradient Boosting\n",
    "importance = gbr.feature_importances_\n",
    "for i, feature in enumerate(features):\n",
    "    print(f\"Feature: {feature}, Importance: {importance[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modeling for White Infant Mortality\n",
      "RMSE: 0.0707\n",
      "R^2: -0.9998\n",
      "Feature Importance:\n",
      "  white_income_edu_interaction: 0.4306\n",
      "  black_white_infant_mortality_ratio: 0.2580\n",
      "  income_inequality: 0.2039\n",
      "  white_income_college_ratio: 0.1075\n",
      "  chronic_risk_index: 0.0000\n",
      "  white_black_wage_gap: 0.0000\n",
      "\n",
      "Modeling for Black Infant Mortality\n",
      "RMSE: 0.0707\n",
      "R^2: 0.0000\n",
      "Feature Importance:\n",
      "  black_income_edu_interaction: 0.4306\n",
      "  black_white_infant_mortality_ratio: 0.2580\n",
      "  income_inequality: 0.2039\n",
      "  black_income_college_ratio: 0.1075\n",
      "  chronic_risk_index: 0.0000\n",
      "  white_black_wage_gap: 0.0000\n",
      "\n",
      "Modeling for Asian Infant Mortality\n",
      "RMSE: 0.0707\n",
      "R^2: 0.8750\n",
      "Feature Importance:\n",
      "  asian_income_edu_interaction: 0.4306\n",
      "  black_white_infant_mortality_ratio: 0.2580\n",
      "  income_inequality: 0.2039\n",
      "  asian_income_college_ratio: 0.1075\n",
      "  chronic_risk_index: 0.0000\n",
      "  white_black_wage_gap: 0.0000\n",
      "\n",
      "Modeling for Hispanic Infant Mortality\n",
      "RMSE: 0.1424\n",
      "R^2: -7.1078\n",
      "Feature Importance:\n",
      "  hispanic_income_edu_interaction: 0.6070\n",
      "  income_inequality: 0.2136\n",
      "  hispanic_income_college_ratio: 0.1414\n",
      "  chronic_risk_index: 0.0228\n",
      "  black_white_infant_mortality_ratio: 0.0114\n",
      "  white_black_wage_gap: 0.0038\n",
      "\n",
      "Summary of Results:\n",
      "\n",
      "White Infant Mortality\n",
      "  RMSE: 0.0707\n",
      "  R^2: -0.9998\n",
      "  Feature Importance:\n",
      "    white_income_edu_interaction: 0.4306\n",
      "    black_white_infant_mortality_ratio: 0.2580\n",
      "    income_inequality: 0.2039\n",
      "    white_income_college_ratio: 0.1075\n",
      "    chronic_risk_index: 0.0000\n",
      "    white_black_wage_gap: 0.0000\n",
      "\n",
      "Black Infant Mortality\n",
      "  RMSE: 0.0707\n",
      "  R^2: 0.0000\n",
      "  Feature Importance:\n",
      "    black_income_edu_interaction: 0.4306\n",
      "    black_white_infant_mortality_ratio: 0.2580\n",
      "    income_inequality: 0.2039\n",
      "    black_income_college_ratio: 0.1075\n",
      "    chronic_risk_index: 0.0000\n",
      "    white_black_wage_gap: 0.0000\n",
      "\n",
      "Asian Infant Mortality\n",
      "  RMSE: 0.0707\n",
      "  R^2: 0.8750\n",
      "  Feature Importance:\n",
      "    asian_income_edu_interaction: 0.4306\n",
      "    black_white_infant_mortality_ratio: 0.2580\n",
      "    income_inequality: 0.2039\n",
      "    asian_income_college_ratio: 0.1075\n",
      "    chronic_risk_index: 0.0000\n",
      "    white_black_wage_gap: 0.0000\n",
      "\n",
      "Hispanic Infant Mortality\n",
      "  RMSE: 0.1424\n",
      "  R^2: -7.1078\n",
      "  Feature Importance:\n",
      "    hispanic_income_edu_interaction: 0.6070\n",
      "    income_inequality: 0.2136\n",
      "    hispanic_income_college_ratio: 0.1414\n",
      "    chronic_risk_index: 0.0228\n",
      "    black_white_infant_mortality_ratio: 0.0114\n",
      "    white_black_wage_gap: 0.0038\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "\n",
    "# Define specific mappings for racial groups based on the data dictionary\n",
    "racial_groups = {\n",
    "    \"white\": \"all_infant_deaths_white\",\n",
    "    \"black\": \"all_infant_deaths_black\",\n",
    "    \"asian\": \"all_infant_deaths_asian_or_pacific_islander\",\n",
    "    \"hispanic\": \"all_infant_deaths_all_races__hispanic\"\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for group, target in racial_groups.items():\n",
    "    print(f\"\\nModeling for {group.title()} Infant Mortality\")\n",
    "\n",
    "    # Define features specific to the group\n",
    "    if group == \"asian\":\n",
    "        income_col = f\"{group}_income_college_ratio\"\n",
    "        edu_interaction = f\"{group}_income_edu_interaction\"\n",
    "    elif group == \"hispanic\":\n",
    "        income_col = \"hispanic_income_college_ratio\"\n",
    "        edu_interaction = \"hispanic_income_edu_interaction\"\n",
    "    else:\n",
    "        income_col = f\"{group}_income_college_ratio\"\n",
    "        edu_interaction = f\"{group}_income_edu_interaction\"\n",
    "\n",
    "    features = [\n",
    "        edu_interaction, income_col, \"income_inequality\",\n",
    "        \"chronic_risk_index\", \"black_white_infant_mortality_ratio\", \"white_black_wage_gap\"\n",
    "    ]\n",
    "\n",
    "    # Ensure target and features exist\n",
    "    if target not in df.columns or any(feature not in df.columns for feature in features):\n",
    "        print(f\"Skipping {group} due to missing data.\")\n",
    "        continue\n",
    "\n",
    "    # Drop rows with missing values in features or target\n",
    "    data = df[features + [target]].dropna()\n",
    "\n",
    "    # Split the data\n",
    "    X = data[features]\n",
    "    y = data[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train Gradient Boosted Regressor\n",
    "    gbr = GradientBoostingRegressor(random_state=42)\n",
    "    gbr.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = gbr.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"R^2: {r2:.4f}\")\n",
    "\n",
    "    # Feature Importance\n",
    "    importance = gbr.feature_importances_\n",
    "    feature_importance = dict(zip(features, importance))\n",
    "    sorted_importance = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print(\"Feature Importance:\")\n",
    "    for feature, importance in sorted_importance:\n",
    "        print(f\"  {feature}: {importance:.4f}\")\n",
    "\n",
    "    # Save results\n",
    "    results[group] = {\n",
    "        \"rmse\": rmse,\n",
    "        \"r2\": r2,\n",
    "        \"feature_importance\": sorted_importance\n",
    "    }\n",
    "\n",
    "# Summarize results\n",
    "print(\"\\nSummary of Results:\")\n",
    "for group, result in results.items():\n",
    "    print(f\"\\n{group.title()} Infant Mortality\")\n",
    "    print(f\"  RMSE: {result['rmse']:.4f}\")\n",
    "    print(f\"  R^2: {result['r2']:.4f}\")\n",
    "    print(f\"  Feature Importance:\")\n",
    "    for feature, importance in result['feature_importance']:\n",
    "        print(f\"    {feature}: {importance:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
